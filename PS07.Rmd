---
title: "STAT/MATH 495: Problem Set 07"
author: "Sara Culhane"
date: "2017-10-24"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE
  )
set.seed(76)

# Load packages
library(tidyverse)
library(broom)
library(knitr)

train <- read_csv("data/cs-training.csv") %>% 
  rename(Id = X1)
test <- read_csv("data/cs-test.csv") %>% 
  rename(Id = X1)
submission <- read_csv("data/sampleEntry.csv")
```

Information on the competition can be found [here](https://www.kaggle.com/c/GiveMeSomeCredit/data).



# Collaboration

Please indicate who you collaborated with on this assignment: 



# Build binary classifier

Build the binary classifier based on a single predictor variable: `DebtRatio`,
`age`, or `MonthlyIncome`. Justify this choice.
```{r}
ggplot(train, aes(x=DebtRatio, y=SeriousDlqin2yrs)) + geom_point()
ggplot(train, aes(x=age, y=SeriousDlqin2yrs)) + geom_point()
ggplot(train, aes(x=MonthlyIncome, y=SeriousDlqin2yrs)) + geom_point()
```

Here, the distribution of MonthlyIncome appears to be the most compelling predictor for predicting default, as it seems that once you hit a certain level of monthly income, no one defaults. Unfortunately,it might be difficult to predict for low incomes, and many probabilities are NA when calculated.Because of the missing data, I choose DebtRatio, as it appears less random than age.

```{r}
model_formula <- as.formula(SeriousDlqin2yrs ~ DebtRatio)
model_logistic <- glm(model_formula, data=train, family="binomial")

model_logistic %>% 
  broom::augment(newdata=test) %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1 + exp(-.fitted))) %>% 
  mutate(SeriousDlqin2yrs = ifelse(p_hat<0.06773,1,0)) %>% 
  sample_n(10)

fitted_model <- model_logistic %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1 + exp(-.fitted)))
predictions <- model_logistic %>% 
  broom::augment(newdata=test) %>% 
  mutate(p_hat = 1/(1 + exp(-.fitted)))

ggplot(NULL) +
  geom_line(data=fitted_model, aes(x=DebtRatio, y=.fitted), col="blue") +
  geom_point(data=predictions, aes(x=DebtRatio, y=.fitted), col="red") +
  labs(x="Debt Ratio", y="Fitted log-odds of p_hat", title="Fitted log-odds of probability of being SeriousDlqin2yrs vs debt ratio")
```

```{r}
sub <- fitted_model %>% 
  mutate(Id = 1:nrow(fitted_model)) %>% 
  mutate(Probability = p_hat) %>% 
  select(Id,Probability)
sub <- sub[1:101503,]
library(readr)
write_csv(sub,"submission.csv")
```



```{r}
ggplot(NULL) +
  # Add observed binary y's, and put a little random jitter to the points
  geom_jitter(data=fitted_model, aes(x=DebtRatio, y=SeriousDlqin2yrs), height=0.05, alpha=0.05) +
  geom_line(data=fitted_model, aes(x=DebtRatio, y=p_hat), col="blue") +
  geom_point(data=predictions, aes(x=DebtRatio, y=p_hat), col="red") +
  labs(x="DebtRatio", y="p_hat", title="Fitted probability of being Serious Dlqqin vs Monthly Income")
```



# ROC curve

Based on the ultimate classifier you choose, plot a corresponding ROC curve.

```{r}
model_roc <- model_logistic %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1+exp(-.fitted)))

library(ROCR)
# This bit of code computes the ROC curve
pred <- prediction(predictions = model_roc$p_hat, labels = model_roc$SeriousDlqin2yrs)
perf <- performance(pred, "tpr","fpr")

# This bit of code computes the Area Under the Curve
auc <- as.numeric(performance(pred,"auc")@y.values)
auc
plot(perf, main=paste("Area Under the Curve =", round(auc, 3)))
abline(c(0, 1), lty=2)
```



# ROC curve for random guessing

Instead of using any predictor information as you did above, switch your
predictions to random guesses and plot the resulting ROC curve.

```{r}
x <- c(0,1)
model_r <- model_logistic %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1+exp(-.fitted))) %>% 
  mutate(y = sample(x,150000 , replace=TRUE))

perf <- performance(pred, "tpr","fpr")

auc <- as.numeric(performance(pred,"auc")@y.values)
auc
plot(perf, main=paste("Area Under the Curve =", round(auc, 3)))
abline(c(0, 1), lty=2)
```

Random guessing performs marginally better than our fitted curve.